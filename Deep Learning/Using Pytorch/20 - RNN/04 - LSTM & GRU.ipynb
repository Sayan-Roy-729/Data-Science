{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"j7-LiwqUMGYL"},"outputs":[],"source":["### import libraries\n","import torch\n","import torch.nn as nn\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"xxH9iWl34bmR"},"source":["# Explore the LSTM type"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"zTIEHcqz4e6b"},"outputs":[{"data":{"text/plain":["LSTM(9, 16, num_layers=2)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# set layer parameters\n","input_size  =  9 # number of features to extract (e.g., number of data channels)\n","hidden_size = 16 # number of units in the hidden state\n","num_layers  =  2 # number of vertical stacks of hidden layers (note: only the final layer gives an output)\n","\n","# create an LSTM instance\n","lstm = nn.LSTM(input_size, hidden_size, num_layers)\n","lstm"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"loAF6NFjX6nQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mSource:\u001b[0m        \n","\u001b[1;32mclass\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;34mr\"\"\"Applies a multi-layer long short-term memory (LSTM) RNN to an input\n","    sequence.\n","\n","\n","    For each element in the input sequence, each layer computes the following\n","    function:\n","\n","    .. math::\n","        \\begin{array}{ll} \\\\\n","            i_t = \\sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{t-1} + b_{hi}) \\\\\n","            f_t = \\sigma(W_{if} x_t + b_{if} + W_{hf} h_{t-1} + b_{hf}) \\\\\n","            g_t = \\tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{t-1} + b_{hg}) \\\\\n","            o_t = \\sigma(W_{io} x_t + b_{io} + W_{ho} h_{t-1} + b_{ho}) \\\\\n","            c_t = f_t \\odot c_{t-1} + i_t \\odot g_t \\\\\n","            h_t = o_t \\odot \\tanh(c_t) \\\\\n","        \\end{array}\n","\n","    where :math:`h_t` is the hidden state at time `t`, :math:`c_t` is the cell\n","    state at time `t`, :math:`x_t` is the input at time `t`, :math:`h_{t-1}`\n","    is the hidden state of the layer at time `t-1` or the initial hidden\n","    state at time `0`, and :math:`i_t`, :math:`f_t`, :math:`g_t`,\n","    :math:`o_t` are the input, forget, cell, and output gates, respectively.\n","    :math:`\\sigma` is the sigmoid function, and :math:`\\odot` is the Hadamard product.\n","\n","    In a multilayer LSTM, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n","    (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n","    dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n","    variable which is :math:`0` with probability :attr:`dropout`.\n","\n","    If ``proj_size > 0`` is specified, LSTM with projections will be used. This changes\n","    the LSTM cell in the following way. First, the dimension of :math:`h_t` will be changed from\n","    ``hidden_size`` to ``proj_size`` (dimensions of :math:`W_{hi}` will be changed accordingly).\n","    Second, the output hidden state of each layer will be multiplied by a learnable projection\n","    matrix: :math:`h_t = W_{hr}h_t`. Note that as a consequence of this, the output\n","    of LSTM network will be of different shape as well. See Inputs/Outputs sections below for exact\n","    dimensions of all variables. You can find more details in https://arxiv.org/abs/1402.1128.\n","\n","    Args:\n","        input_size: The number of expected features in the input `x`\n","        hidden_size: The number of features in the hidden state `h`\n","        num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n","            would mean stacking two LSTMs together to form a `stacked LSTM`,\n","            with the second LSTM taking in outputs of the first LSTM and\n","            computing the final results. Default: 1\n","        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n","            Default: ``True``\n","        batch_first: If ``True``, then the input and output tensors are provided\n","            as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n","            Note that this does not apply to hidden or cell states. See the\n","            Inputs/Outputs sections below for details.  Default: ``False``\n","        dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n","            LSTM layer except the last layer, with dropout probability equal to\n","            :attr:`dropout`. Default: 0\n","        bidirectional: If ``True``, becomes a bidirectional LSTM. Default: ``False``\n","        proj_size: If ``> 0``, will use LSTM with projections of corresponding size. Default: 0\n","\n","    Inputs: input, (h_0, c_0)\n","        * **input**: tensor of shape :math:`(L, H_{in})` for unbatched input,\n","          :math:`(L, N, H_{in})` when ``batch_first=False`` or\n","          :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n","          the input sequence.  The input can also be a packed variable length sequence.\n","          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n","          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n","        * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n","          :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the\n","          initial hidden state for each element in the input sequence.\n","          Defaults to zeros if (h_0, c_0) is not provided.\n","        * **c_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{cell})` for unbatched input or\n","          :math:`(D * \\text{num\\_layers}, N, H_{cell})` containing the\n","          initial cell state for each element in the input sequence.\n","          Defaults to zeros if (h_0, c_0) is not provided.\n","\n","        where:\n","\n","        .. math::\n","            \\begin{aligned}\n","                N ={} & \\text{batch size} \\\\\n","                L ={} & \\text{sequence length} \\\\\n","                D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n","                H_{in} ={} & \\text{input\\_size} \\\\\n","                H_{cell} ={} & \\text{hidden\\_size} \\\\\n","                H_{out} ={} & \\text{proj\\_size if } \\text{proj\\_size}>0 \\text{ otherwise hidden\\_size} \\\\\n","            \\end{aligned}\n","\n","    Outputs: output, (h_n, c_n)\n","        * **output**: tensor of shape :math:`(L, D * H_{out})` for unbatched input,\n","          :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n","          :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n","          `(h_t)` from the last layer of the LSTM, for each `t`. If a\n","          :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n","          will also be a packed sequence. When ``bidirectional=True``, `output` will contain\n","          a concatenation of the forward and reverse hidden states at each time step in the sequence.\n","        * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` for unbatched input or\n","          :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the\n","          final hidden state for each element in the sequence. When ``bidirectional=True``,\n","          `h_n` will contain a concatenation of the final forward and reverse hidden states, respectively.\n","        * **c_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{cell})` for unbatched input or\n","          :math:`(D * \\text{num\\_layers}, N, H_{cell})` containing the\n","          final cell state for each element in the sequence. When ``bidirectional=True``,\n","          `c_n` will contain a concatenation of the final forward and reverse cell states, respectively.\n","\n","    Attributes:\n","        weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n","            `(W_ii|W_if|W_ig|W_io)`, of shape `(4*hidden_size, input_size)` for `k = 0`.\n","            Otherwise, the shape is `(4*hidden_size, num_directions * hidden_size)`. If\n","            ``proj_size > 0`` was specified, the shape will be\n","            `(4*hidden_size, num_directions * proj_size)` for `k > 0`\n","        weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n","            `(W_hi|W_hf|W_hg|W_ho)`, of shape `(4*hidden_size, hidden_size)`. If ``proj_size > 0``\n","            was specified, the shape will be `(4*hidden_size, proj_size)`.\n","        bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n","            `(b_ii|b_if|b_ig|b_io)`, of shape `(4*hidden_size)`\n","        bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n","            `(b_hi|b_hf|b_hg|b_ho)`, of shape `(4*hidden_size)`\n","        weight_hr_l[k] : the learnable projection weights of the :math:`\\text{k}^{th}` layer\n","            of shape `(proj_size, hidden_size)`. Only present when ``proj_size > 0`` was\n","            specified.\n","        weight_ih_l[k]_reverse: Analogous to `weight_ih_l[k]` for the reverse direction.\n","            Only present when ``bidirectional=True``.\n","        weight_hh_l[k]_reverse:  Analogous to `weight_hh_l[k]` for the reverse direction.\n","            Only present when ``bidirectional=True``.\n","        bias_ih_l[k]_reverse:  Analogous to `bias_ih_l[k]` for the reverse direction.\n","            Only present when ``bidirectional=True``.\n","        bias_hh_l[k]_reverse:  Analogous to `bias_hh_l[k]` for the reverse direction.\n","            Only present when ``bidirectional=True``.\n","        weight_hr_l[k]_reverse:  Analogous to `weight_hr_l[k]` for the reverse direction.\n","            Only present when ``bidirectional=True`` and ``proj_size > 0`` was specified.\n","\n","    .. note::\n","        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n","        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n","\n","    .. note::\n","        For bidirectional LSTMs, forward and backward are directions 0 and 1 respectively.\n","        Example of splitting the output layers when ``batch_first=False``:\n","        ``output.view(seq_len, batch, num_directions, hidden_size)``.\n","\n","    .. note::\n","        For bidirectional LSTMs, `h_n` is not equivalent to the last element of `output`; the\n","        former contains the final forward and reverse hidden states, while the latter contains the\n","        final forward hidden state and the initial reverse hidden state.\n","\n","    .. note::\n","        ``batch_first`` argument is ignored for unbatched inputs.\n","\n","    .. include:: ../cudnn_rnn_determinism.rst\n","\n","    .. include:: ../cudnn_persistent_rnn.rst\n","\n","    Examples::\n","\n","        >>> rnn = nn.LSTM(10, 20, 2)\n","        >>> input = torch.randn(5, 3, 10)\n","        >>> h0 = torch.randn(2, 3, 20)\n","        >>> c0 = torch.randn(2, 3, 20)\n","        >>> output, (hn, cn) = rnn(input, (h0, c0))\n","    \"\"\"\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LSTM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mget_expected_cell_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmini_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmini_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mnum_directions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                                \u001b[0mmini_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# In the future, we should prevent mypy from applying contravariance rules here.\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# See torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[override]\u001b[0m\u001b[1;33m\n","\u001b[0m                           \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                           \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                           \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                           \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                               \u001b[1;34m'Expected hidden[0] size {}, got {}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_cell_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                               \u001b[1;34m'Expected hidden[1] size {}, got {}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Same as above, see torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[override]\u001b[0m\u001b[1;33m\n","\u001b[0m                       \u001b[0mhx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                       \u001b[0mpermutation\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m                       \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mpermutation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0m_apply_permutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_apply_permutation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Same as above, see torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m  \u001b[1;31m# type: ignore[override]\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overload_method\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mpass\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;31m# Same as above, see torch/nn/modules/module.py::_forward_unimplemented\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overload_method\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mpass\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0morig_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# xxx: isinstance check needs to be in conditional for TorchScript to compile\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mis_batched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mbatch_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0msorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mnum_directions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mreal_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproj_size\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproj_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mh_zeros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                                  \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                                  \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mc_zeros\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                                  \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                                  \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh_zeros\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc_zeros\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# If not PackedSequence input.\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                        \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"For batched 3-D input, hx and cx should \"\u001b[0m\u001b[1;33m\n","\u001b[0m                               \u001b[1;34mf\"also be 3-D but got ({hx[0].dim()}-D, {hx[1].dim()}-D) tensors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                        \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                        \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"For unbatched 2-D input, hx and cx should \"\u001b[0m\u001b[1;33m\n","\u001b[0m                               \u001b[1;34mf\"also be 2-D but got ({hx[0].dim()}-D, {hx[1].dim()}-D) tensors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                        \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                    \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;31m# Each batch of the hidden state should match the input sequence that\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;31m# the user believes he/she is passing in.\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# xxx: isinstance check needs to be in conditional for TorchScript to compile\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0moutput_packed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0moutput_packed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFile:\u001b[0m           c:\\users\\sayan\\documents\\ds_venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\n","\u001b[1;31mType:\u001b[0m           type\n","\u001b[1;31mSubclasses:\u001b[0m     "]}],"source":["# check out the source code for more detailed info about this class\n","??nn.LSTM"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nPMVY6Em5B7y"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Input shape: [5, 2, 9]\n","Hidden shape: [2, 2, 16]\n","  Cell shape: [2, 2, 16]\n","Output shape: [5, 2, 16]\n"]}],"source":["# set data parameters\n","seqlength = 5\n","batchsize = 2\n","\n","# create some data\n","X = torch.rand(seqlength,batchsize,input_size)\n","\n","# create initial hidden states (typically initialized as zeros)\n","H = torch.zeros(num_layers,batchsize,hidden_size)\n","C = torch.zeros(num_layers,batchsize,hidden_size)\n","\n","# the input is actually a tuple of (hidden,cell)\n","hiddeninputs = (H, C)\n","\n","# run some data through the model and show the output sizes\n","y,h = lstm(X,hiddeninputs)\n","print(f' Input shape: {list(X.shape)}')\n","print(f'Hidden shape: {list(h[0].shape)}')\n","print(f'  Cell shape: {list(h[1].shape)}')\n","print(f'Output shape: {list(y.shape)}')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"-NO2PlZx_R2m"},"outputs":[{"name":"stdout","output_type":"stream","text":["weight_ih_l0 has size [64, 9]\n","weight_hh_l0 has size [64, 16]\n","weight_ih_l1 has size [64, 16]\n","weight_hh_l1 has size [64, 16]\n"]}],"source":["# Check out the learned parameters and their sizes\n","for p in lstm.named_parameters():\n","  if 'weight' in p[0]:\n","    print(f'{p[0]} has size {list(p[1].shape)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0pFPzSU4MSGg"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"VToReEHNWP0n"},"source":["# Create a DL model class"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"RVcrKOC1Wqk-"},"outputs":[],"source":["class LSTMnet(nn.Module):\n","  def __init__(self,input_size,num_hidden,num_layers):\n","    super().__init__()\n","\n","    # store parameters\n","    self.input_size = input_size\n","    self.num_hidden = num_hidden\n","    self.num_layers = num_layers\n","\n","    # RNN Layer (notation: LSTM \\in RNN)\n","    self.lstm = nn.LSTM(input_size,num_hidden,num_layers)\n","    \n","    # linear layer for output\n","    self.out = nn.Linear(num_hidden, 1)\n","  \n","  def forward(self,x):\n","    \n","    print(f'Input: {list(x.shape)}')\n","\n","    # run through the RNN layer\n","    y,hidden = self.lstm(x)\n","    print(f'RNN-out: {list(y.shape)}')\n","    print(f'RNN-hidden: {list(hidden[0].shape)}')\n","    print(f'RNN-cell: {list(hidden[1].shape)}')\n","    \n","    # pass the RNN output through the linear output layer\n","    o = self.out(y)\n","    print(f'Output: {list(o.shape)}')\n","\n","    return o,hidden"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"zQKkLPUeWqn_"},"outputs":[{"name":"stdout","output_type":"stream","text":["LSTMnet(\n","  (lstm): LSTM(9, 16, num_layers=2)\n","  (out): Linear(in_features=16, out_features=1, bias=True)\n",")\n"," \n","   lstm.weight_ih_l0 has size [64, 9]\n","   lstm.weight_hh_l0 has size [64, 16]\n","     lstm.bias_ih_l0 has size [64]\n","     lstm.bias_hh_l0 has size [64]\n","   lstm.weight_ih_l1 has size [64, 16]\n","   lstm.weight_hh_l1 has size [64, 16]\n","     lstm.bias_ih_l1 has size [64]\n","     lstm.bias_hh_l1 has size [64]\n","          out.weight has size [1, 16]\n","            out.bias has size [1]\n"]}],"source":["# create an instance of the model and inspect\n","net = LSTMnet(input_size,hidden_size,num_layers)\n","print(net), print(' ')\n","\n","# and check out all learnable parameters\n","for p in net.named_parameters():\n","  print(f'{p[0]:>20} has size {list(p[1].shape)}')"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0WL8wjwn0Jwr"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input: [5, 2, 9]\n","RNN-out: [5, 2, 16]\n","RNN-hidden: [2, 2, 16]\n","RNN-cell: [2, 2, 16]\n","Output: [5, 2, 1]\n"]},{"data":{"text/plain":["tensor(0.3819, grad_fn=<MseLossBackward0>)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# test the model with some data\n","# create some data\n","X = torch.rand(seqlength,batchsize,input_size)\n","y = torch.rand(seqlength,batchsize,1)\n","yHat,h = net(X)\n","\n","\n","lossfun = nn.MSELoss()\n","lossfun(yHat,y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXtU8uw-_7P0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bdQ9d5UC_7Ss"},"source":["# GRU"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"DclTJD17-66o"},"outputs":[{"data":{"text/plain":["GRU(9, 16, num_layers=2)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# create a GRU instance\n","gru = nn.GRU(input_size, hidden_size, num_layers)\n","gru"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"8irbAyPitaUI"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mSource:\u001b[0m        \n","\u001b[1;32mclass\u001b[0m \u001b[0mGRU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;34mr\"\"\"Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.\n","\n","\n","    For each element in the input sequence, each layer computes the following\n","    function:\n","\n","    .. math::\n","        \\begin{array}{ll}\n","            r_t = \\sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\\\\n","            z_t = \\sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\\\\n","            n_t = \\tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\\\\n","            h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}\n","        \\end{array}\n","\n","    where :math:`h_t` is the hidden state at time `t`, :math:`x_t` is the input\n","    at time `t`, :math:`h_{(t-1)}` is the hidden state of the layer\n","    at time `t-1` or the initial hidden state at time `0`, and :math:`r_t`,\n","    :math:`z_t`, :math:`n_t` are the reset, update, and new gates, respectively.\n","    :math:`\\sigma` is the sigmoid function, and :math:`*` is the Hadamard product.\n","\n","    In a multilayer GRU, the input :math:`x^{(l)}_t` of the :math:`l` -th layer\n","    (:math:`l >= 2`) is the hidden state :math:`h^{(l-1)}_t` of the previous layer multiplied by\n","    dropout :math:`\\delta^{(l-1)}_t` where each :math:`\\delta^{(l-1)}_t` is a Bernoulli random\n","    variable which is :math:`0` with probability :attr:`dropout`.\n","\n","    Args:\n","        input_size: The number of expected features in the input `x`\n","        hidden_size: The number of features in the hidden state `h`\n","        num_layers: Number of recurrent layers. E.g., setting ``num_layers=2``\n","            would mean stacking two GRUs together to form a `stacked GRU`,\n","            with the second GRU taking in outputs of the first GRU and\n","            computing the final results. Default: 1\n","        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n","            Default: ``True``\n","        batch_first: If ``True``, then the input and output tensors are provided\n","            as `(batch, seq, feature)` instead of `(seq, batch, feature)`.\n","            Note that this does not apply to hidden or cell states. See the\n","            Inputs/Outputs sections below for details.  Default: ``False``\n","        dropout: If non-zero, introduces a `Dropout` layer on the outputs of each\n","            GRU layer except the last layer, with dropout probability equal to\n","            :attr:`dropout`. Default: 0\n","        bidirectional: If ``True``, becomes a bidirectional GRU. Default: ``False``\n","\n","    Inputs: input, h_0\n","        * **input**: tensor of shape :math:`(L, H_{in})` for unbatched input,\n","          :math:`(L, N, H_{in})` when ``batch_first=False`` or\n","          :math:`(N, L, H_{in})` when ``batch_first=True`` containing the features of\n","          the input sequence.  The input can also be a packed variable length sequence.\n","          See :func:`torch.nn.utils.rnn.pack_padded_sequence` or\n","          :func:`torch.nn.utils.rnn.pack_sequence` for details.\n","        * **h_0**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` or\n","          :math:`(D * \\text{num\\_layers}, N, H_{out})`\n","          containing the initial hidden state for the input sequence. Defaults to zeros if not provided.\n","\n","        where:\n","\n","        .. math::\n","            \\begin{aligned}\n","                N ={} & \\text{batch size} \\\\\n","                L ={} & \\text{sequence length} \\\\\n","                D ={} & 2 \\text{ if bidirectional=True otherwise } 1 \\\\\n","                H_{in} ={} & \\text{input\\_size} \\\\\n","                H_{out} ={} & \\text{hidden\\_size}\n","            \\end{aligned}\n","\n","    Outputs: output, h_n\n","        * **output**: tensor of shape :math:`(L, D * H_{out})` for unbatched input,\n","          :math:`(L, N, D * H_{out})` when ``batch_first=False`` or\n","          :math:`(N, L, D * H_{out})` when ``batch_first=True`` containing the output features\n","          `(h_t)` from the last layer of the GRU, for each `t`. If a\n","          :class:`torch.nn.utils.rnn.PackedSequence` has been given as the input, the output\n","          will also be a packed sequence.\n","        * **h_n**: tensor of shape :math:`(D * \\text{num\\_layers}, H_{out})` or\n","          :math:`(D * \\text{num\\_layers}, N, H_{out})` containing the final hidden state\n","          for the input sequence.\n","\n","    Attributes:\n","        weight_ih_l[k] : the learnable input-hidden weights of the :math:`\\text{k}^{th}` layer\n","            (W_ir|W_iz|W_in), of shape `(3*hidden_size, input_size)` for `k = 0`.\n","            Otherwise, the shape is `(3*hidden_size, num_directions * hidden_size)`\n","        weight_hh_l[k] : the learnable hidden-hidden weights of the :math:`\\text{k}^{th}` layer\n","            (W_hr|W_hz|W_hn), of shape `(3*hidden_size, hidden_size)`\n","        bias_ih_l[k] : the learnable input-hidden bias of the :math:`\\text{k}^{th}` layer\n","            (b_ir|b_iz|b_in), of shape `(3*hidden_size)`\n","        bias_hh_l[k] : the learnable hidden-hidden bias of the :math:`\\text{k}^{th}` layer\n","            (b_hr|b_hz|b_hn), of shape `(3*hidden_size)`\n","\n","    .. note::\n","        All the weights and biases are initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`\n","        where :math:`k = \\frac{1}{\\text{hidden\\_size}}`\n","\n","    .. note::\n","        For bidirectional GRUs, forward and backward are directions 0 and 1 respectively.\n","        Example of splitting the output layers when ``batch_first=False``:\n","        ``output.view(seq_len, batch, num_directions, hidden_size)``.\n","\n","    .. note::\n","        ``batch_first`` argument is ignored for unbatched inputs.\n","\n","    .. include:: ../cudnn_persistent_rnn.rst\n","\n","    Examples::\n","\n","        >>> rnn = nn.GRU(10, 20, 2)\n","        >>> input = torch.randn(5, 3, 10)\n","        >>> h0 = torch.randn(2, 3, 20)\n","        >>> output, hn = rnn(input, h0)\n","    \"\"\"\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[1;34m'proj_size'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"proj_size argument is only supported for LSTM, not RNN or GRU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GRU'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m  \u001b[1;31m# type: ignore[override]\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overload_method\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mpass\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;33m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overload_method\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPackedSequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mpass\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0morig_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# xxx: isinstance check needs to be in conditional for TorchScript to compile\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mbatch_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mis_batched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mbatch_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                        \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n","\u001b[0m                            \u001b[1;34mf\"For unbatched 2-D input, hx should also be 2-D but got {hx.dim()}-D tensor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                    \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                    \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n","\u001b[0m                        \u001b[1;34mf\"For batched 3-D input, hx should also be 3-D but got {hx.dim()}-D tensor\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mmax_batch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0msorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mnum_directions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_directions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                             \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;31m# Each batch of the hidden state should match the input sequence that\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;31m# the user believes he/she is passing in.\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flat_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n","\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;31m# xxx: isinstance check needs to be in conditional for TorchScript to compile\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[0moutput_packed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0moutput_packed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m        \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m                \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n","\u001b[0m\u001b[1;33m\n","\u001b[0m            \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mFile:\u001b[0m           c:\\users\\sayan\\documents\\ds_venv\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\n","\u001b[1;31mType:\u001b[0m           type\n","\u001b[1;31mSubclasses:\u001b[0m     "]}],"source":["??nn.GRU"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"sg-G5f2g-69O"},"outputs":[{"name":"stdout","output_type":"stream","text":[" Input shape: [5, 2, 9]\n","Hidden shape: [2, 2, 16]\n","Output shape: [5, 2, 16]\n"]}],"source":["# create some data and a hidden state\n","X = torch.rand(seqlength,batchsize,input_size)\n","H = torch.zeros(num_layers,batchsize,hidden_size)\n","\n","# run some data through the model and show the output sizes\n","y,h = gru(X,H) # No cell states in GRU!\n","print(f' Input shape: {list(X.shape)}')\n","print(f'Hidden shape: {list(h.shape)}')\n","print(f'Output shape: {list(y.shape)}')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"qd9y5lT4snEQ"},"outputs":[{"name":"stdout","output_type":"stream","text":["   weight_ih_l0 has size [48, 9]\n","   weight_hh_l0 has size [48, 16]\n","     bias_ih_l0 has size [48]\n","     bias_hh_l0 has size [48]\n","   weight_ih_l1 has size [48, 16]\n","   weight_hh_l1 has size [48, 16]\n","     bias_ih_l1 has size [48]\n","     bias_hh_l1 has size [48]\n"]}],"source":["# Check out the learned parameters and their sizes\n","for p in gru.named_parameters():\n","  print(f'{p[0]:>15} has size {list(p[1].shape)}')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO91pz9QDJtavwD0WQf3cvo","collapsed_sections":[],"name":"DUDL_RNN_LSTMGRU.ipynb","provenance":[{"file_id":"19WUFNKOHKnZ1hEkR6havrl_eIE4BxuaE","timestamp":1635419946139},{"file_id":"1BI9p-vnVoi7Tm8yiQgVN3kpM2VuEzfeE","timestamp":1621245811372},{"file_id":"1o_dLKV6fY7xdZYx_pNMY12zpL_pmMurs","timestamp":1618865813618},{"file_id":"1Q9LtmanyNt675-gO_kXRBKalCdP6xtvV","timestamp":1617253457100},{"file_id":"1jeqKEJfI18GlAhSG8RO5aJ6Vrp4-nkTt","timestamp":1615909315432},{"file_id":"10_geQnah5AvMsm8VDAQwNPhypOXradar","timestamp":1615893340208},{"file_id":"1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD","timestamp":1615877547147}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
